# Table of Contents
1. [Generating RDS](#generating-rds)
2. [Loading Data to Siku from AWS](#loading-data-to-siku-from-aws)
3. [Testing Parallel Functions](#testing-parallel-functions)


## Generating RDS
Code below from original script "Caribou_Indiv_traj_BRB.Rmd". It only runs the winter portion and saves the output for first 4 animals. The output was stored in aws as well to facilitate synchornization to siku.

```{r}
# Load Packages - RAD - removed sf because unable to install on cluster
list.of.packages <- c(
  "foreach",
  "doParallel",
  "ggplot2",
  "here",
  "adehabitatLT",
  "adehabitatHR",
  "stringr",
  "ks",
  "rgdal",
  "terra", 
  "sf", "future")

 # Updated list
list.of.packages <- c(
	"foreach",
	"future",
	"future.apply",
	"future.batchtools",
	"doParallel",
	"rslurm",
	"here",
	"adehabitatLT",
	"adehabitatHR",
	"rgdal",
	"terra",
	"sf"
)

for(package.i in list.of.packages){
  suppressPackageStartupMessages(
    library(
      package.i, 
      character.only = TRUE
      )
    )
}

# RAD: defining the column names for a the data frame

#############################################################################
x = "E" # Easting
y = "N" # Northing
## See depreciated: https://inbo.github.io/tutorials/tutorials/spatial_crs_coding/
crs.proj <- CRS(SRS_string = "EPSG:26910") # For raster formatting
input.projection = "+init=epsg:26910" # For SpatialDataFrame formatting
Datecolumn= "Date"
Timecolumn= "Time"
timezone = "GMT"
loc.output <- paste0("adeHRoutput/")
#############################################################################

##Caribou_Quintette2 <- read.csv(paste0(here("Input Data"), "/Caribou_July2022.csv"), stringsAsFactors = FALSE) # Old
Caribou_BMTR <- read.csv("Input_Data/Caribou_noclip.csv")
# Separating the data into two tables
Caribou_BM <- Caribou_BMTR[which(Caribou_BMTR$SA == "BM"),]
Caribou_TR <- Caribou_BMTR[which(Caribou_BMTR$SA == "TR"),]
# Create a dataframe to hold all of the contents of Caribout.ltraj with a column for id. 
# Put first element into the dataframe
## Bullmoose trajectories
CaribouBM.ltraj <- as.ltraj(xy = Caribou_BM[,c("E", "N")], 
                       date =  as.POSIXct(Caribou_BM$timestamp,
                       format = "%Y-%m-%d %H:%M:%S", tz = "GMT"),
                       id = Caribou_BM$AnimalID, typeII = TRUE)
total.path.df <- data.frame(CaribouBM.ltraj[[1]],
                            id = attr(CaribouBM.ltraj[[1]],
                                      "id"))
# Use a 'for' loop to fill the larger dataframe with the rest of the trajectories.
for(i in 2:length(CaribouBM.ltraj)) {
  total.path.df <- rbind(total.path.df,
                         data.frame(CaribouBM.ltraj[[i]],
                         id = attr(CaribouBM.ltraj[[i]],
                         "id")))
  }
# Calculate distance traveled per day and add it to the dataframe
total.path.df$distperday <- total.path.df$dist / (total.path.df$dt/60/60/24)
# Aggregate to show mean distance per day for each animal
path.summary <- aggregate(distperday~id, data = total.path.df, FUN = mean)
path.summary$sd <- aggregate(distperday~id, data = total.path.df, FUN = sd)$distperday
# Look at summary dataframe
path.summary

## Four season model - 1. EW, MW, LW winter as one, 2. calving, 3. summer, and 4. rutting
## Organize winter as one
years <- unique(Caribou_BMTR$YearSeas)

## Bullmoose winter -------------------------------------------
Caribou_BM_WI <- Caribou_BM[which(Caribou_BM$season == "EW" | Caribou_BM$season == "MW" | Caribou_BM$season == "LW"),]
Caribou_BM_WI_LI <- list()
tally = 1
x = 1
IndID <- data.frame(matrix(ncol=1))
colnames(IndID) <- "ID"
for(y in 1:length(years)){
  if(nrow(data.frame(Caribou_BM_WI[which(Caribou_BM_WI$YearSeas == years[y]), ])) > 0){
    assign("temp",data.frame(Caribou_BM_WI[which(Caribou_BM_WI$YearSeas == years[y]), ]))
    Ind <- unique(temp$AnimalID)
      for(i in 1:length(Ind)){
        if(nrow(temp[which(temp$AnimalID == Ind[i]),]) < 5){  ## Threshold on #track points
          IndID[x,] <- Ind[i]
          x = x + 1
        }else{next()}}
    Caribou_BM_WI_LI[[tally]] <- temp[!temp$AnimalID %in% IndID$ID,]
    names(Caribou_BM_WI_LI)[tally] <- paste0("Caribou_BM_WI_",years[y])
    tally = tally + 1
  }else{next()}
}
Caribou_BM_WI_LI[sapply(Caribou_BM_WI_LI,function(x) all(is.na(x)))] <- NULL

##Winter
BM_WI_Traj <- list()
for(l in 1:length(Caribou_BM_WI_LI)){
  BM_WI_Traj[[l]] <-  as.ltraj(xy = Caribou_BM_WI_LI[[l]][,c("E", "N")], 
                          date =  as.POSIXct(Caribou_BM_WI_LI[[l]]$timestamp,
                          format = "%Y-%m-%d %H:%M:%S", tz = "GMT"),
                          id = Caribou_BM_WI_LI[[l]]$AnimalID,
                          typeII = TRUE)
  names(BM_WI_Traj)[l] <- paste0("BM_WI_",unique(Caribou_BM_WI_LI[[l]]$YearSeas))
  }

############
## BM Winter
## D: diffusion parameter - using ML function:

DLik_BM_WI <- list()
tally = 1
BM_WI_Traj <- BM_WI_Traj[order(names(BM_WI_Traj))]

for(t in 1:length(BM_WI_Traj)){
  DLik_BM_WI[[tally]] <- BRB.likD(BM_WI_Traj[[t]], Tmax=1500*60, Lmin=2,  Dr=c(2,7))
  tally = tally + 1
}

names(DLik_BM_WI) <- names(BM_WI_Traj)
names(DLik_BM_WI[1]) ##"BM_WI_2003"


## DLik_...computes a list of each animal n = observations during the time interval [0,Ttotal], and D- diffusion parameter. See: Horne, J.S., Garton, E.O., Krone, S.M. and Lewis, J.S. 2007. Analyzing animal movements using Brownian bridges. Ecology, 88, 2354â€“235
## These are contained in a list by year

DLik_BM_WI_u <- unlist(DLik_BM_WI)
DLik_BM_WI_u <- DLik_BM_WI_u[1:(length(DLik_BM_WI_u)/2)*2]
DLik_BM_WI_u <- as.numeric(as.vector(DLik_BM_WI_u))

Traj_len <- as.numeric(as.vector(lengths(BM_WI_Traj)))
#> Traj_len
# [1]  2  2  5  5  8  7 11  6 10  5  6  5 10 10 11 16 11 12  8

Traj_li <- vector("list", length(DLik_BM_WI_u))
a = 1
b = 1

for(y in 1:length(Traj_len)){
    b = 1
    while(b <= Traj_len[y]){
        Traj_li[[a]] <- BM_WI_Traj[[y]][b]
        names(Traj_li[[a]])  <- names(BM_WI_Traj[y])
        b = b + 1
        a = a + 1
        }
    }


# RAD -- ABOVE HE IS SETTING UP TH ENVIRONMENBT AND BRINGING DATA IN -- ONLY USING WINTER for CARIBOU

# Note to understand resultant data structure:
#sum(lengths(DLik_BM_WI))
#[1] 150
#sum(Traj_len)
#[1] 150

## The BRBs_BM_WI need to be named. The names are contained here:

# BRB calculation

#create the cluster
# Reduce the number of cores to save mem.
# See: https://stackoverflow.com/questions/28503208/doparallel-error-in-r-error-#in-serializedata-nodecon-error-writing-to-con

n.cores <- parallel::detectCores() - 3
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "FORK"
  )

#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)


system.time({
BRBs_BM_WI <- foreach(i = 1:4,
                      .combine = c,
                      .packages = c("adehabitatHR","adehabitatLT")) %dopar% {
                          BRB(Traj_li[[i]][1],
                          D = DLik_BM_WI_u[i],
                          Tmax = 1500*60,
                          Lmin = 2,
                          hmin = 20,
                          type = "UD",
                          grid = 4000)
                      }
	})
stopCluster(my.cluster)

saveRDS(BRBs_BM_WI, "BRBs_BM_WI.rds")

n.cores <- parallel::detectCores() - 1
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "FORK"
  )
#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)
system.time({
x <- foreach(i = 1:4) %dopar% {
	saveRDS(brb[[i]], paste("animal", as.character(i), ".rds", sep = ""))
		}
	})
stopCluster(my.cluster)
# VS
system.time({
saving <- function(dat, j){
	print(j)
	saveRDS(dat, paste("animal_", as.character(j), ".rds", sep = ""))
}
j <- c(1, 2, 3, 4)
y <- mapply(saving, brb2, j)
})

animal1 <- BRBs_BM_WI[[1]]
animal2 <- BRBs_BM_WI[[2]]
animal3 <- BRBs_BM_WI[[3]]
animal4 <- BRBs_BM_WI[[4]]
saveRDS(animal1, "animal1.rds")
saveRDS(animal2, "animal2.rds")
saveRDS(animal3, "animal3.rds")
saveRDS(animal4, "animal4.rds")

```


## Loading Data to Siku from AWS
In order to speed up testing process the BRBs_BM_WI intermediate was saved on aws and then SIKU was used to synchornize. The code to perform this is shown below. The first chunk installs aws cli, while second shows how to use sync feature.

```{r}
# Installing aws cli tools
wget https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip
unzip awscli-exe-linux-x86_64.zip
aws/install --install-dir ~/aws-cli --bin-dir ~/bin
aws --version
rm -r aws awscli-exe-linux-x86_64.zip
```


```{r}
# To download from aws bucket
aws s3 sync s3://sat-caribou destination_folder

# To upload to aws bucket
aws s3 sync upload-folders3://sat-caribou
```

## Testing Parallel Functions
```{r}
# Memory management
gc()
gcinfo(TRUE)


# Load pre-created data (double list version)
brb <- readRDS("Input_Data/BRBs_BM_WI.rds")

#Load data and generate single list version of data -- workable
animal1 <- readRDS("Input_Data/animal1.rds")
animal2 <- readRDS("Input_Data/animal2.rds")
animal3 <- readRDS("Input_Data/animal3.rds")
animal4 <- readRDS("Input_Data/animal4.rds")
brb2 <- list(animal1, animal2, animal3, animal4)


options(future.globals.maxSize= 2912896000)
brb <- readRDS("BRBs_BM_WI.rds")
j <- c(1, 2, 3, 4)

# Parallel Approach
n.cores <- parallel::detectCores() - 1
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "FORK"
  )
#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)
system.time({
x <- foreach(i = 1:4) %dopar% {
	saveRDS(brb[[i]], paste("animal", as.character(i), ".rds", sep = ""))
		}
	})
stopCluster(my.cluster)
# VS
system.time({
saving <- function(dat, j){
	print(j)
	saveRDS(dat, paste("animal_", as.character(j), ".rds", sep = ""))
}

y <- mapply(saving, brb, j)
})
# Possible reasons
```









MinReproduce
salloc --time 1:00:00 ncores=1 ---mem=0 --cpus-per-task=40
```{r}
data(puechcirc)

pc1 <- puechcirc[1]
pc2 <- puechcirc[2]
pc3 <- puechcirc[3]
Traj_li <- vector("list", 3)
Traj_li[[1]] <- pc1
Traj_li[[2]] <- pc2
Traj_li[[3]] <- pc3
DLik <- c(2.1, 2.2, 4)
thenames <- c("pn1", "pn2", "pn3")

# Create and save the estBRB objects in parallel:

n.cores <- future::availableCores()
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "PSOCK" 
  )

#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)

system.time({
BRBs_BM_WI <- foreach(i = 1:length(Traj_li),
                      .combine = c,
                      .packages = c("adehabitatHR","adehabitatLT", "here")) %dopar% {
                            saveRDS(BRB(Traj_li[[i]][1],
                            D = DLik[i],
                            Tmax = 1500*60,
                            Lmin = 2,
                            hmin = 20,
                            type = "UD",
                            grid = 4000),paste0(here("BRB_UDs"),"/",thenames[i],"toy.Rds"))
                        }})
stopCluster(my.cluster)

# list in the estBRB object files
BRBs_BM_WIf <- list.files(here("BRB_UDs"),
                 pattern="toy.Rds$",
                 full.names=TRUE)

#Area cluster
###########################################################
### future approach, only for node=1, works fastest 311 sec -- RAD gave elapsed 286
plan(multicore)
system.time(BRBs_BM_WI <- lapply(BRBs_BM_WIf, function(x){readRDS(x)}))
system.time(BRBs_BM_WIv <- future_lapply(BRBs_BM_WI, FUN = function(x) {getverticeshr.estUD(x)}))

system.time(for(i in 1:length(thenames)){
	vect(BRBs_BM_WIv[i],paste0(here("BRB_UDs"),"/",thenames[i],"toy_hr.Rds"))})

###########################################################
## parallel approach,370.487 Sec, RAD FORK gave elapsed 330 PSOCK gave elapsed 
n.cores <- as.vector(future::availableCores())
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "PSOCK" ## PSOCK for one node.
  )

#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)

BRBs_BM_WI <- lapply(BRBs_BM_WIf, function(x){readRDS(x)})

system.time({
homerange <- foreach(i = 1:length(BRBs_BM_WI),
                      .combine = c,
                      .packages = c("adehabitatHR","here")) %dopar% {
                      saveRDS(getverticeshr.estUD(BRBs_BM_WI[[i]]),
                              paste0(here("BRB_UDs"),"/",thenames[i],"toy_hr.Rds"))
                        }    
	})
# Stop the parallel backend
stopCluster(my.cluster)

###########################################################
#SlurmR testing these approaches

getvertf <- function(x){
  getverticeshr.estUD(x)
}

n.cores <- as.vector(future::availableCores())

system.time(
BRBs_BM_WIv <- slurm_map(BRBs_BM_WI,
                  getvertf,
                  nodes = 3, cpus_per_task = n.cores)
)

##
# I note with future, you can plan. This requires from bash
# look at the nodes and their names:
# >sq
# >scontrol show nodes cl['name of the first node'-'name of the last node']
# e.g., for 3 Siku nodes: cl[064-066]
# This does not work, but it should:
plan(cluster, workers = c("cl064", "cl065", "cl066")) # get the names of the nodes from bash in interactive assign.


```